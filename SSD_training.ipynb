{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f724982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981f52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9313ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备为cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'当前设备为{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40617541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123)  \n",
    "input_size = 300 \n",
    "#dataset\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 6\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
    "\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de47d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备为 cuda:0\n",
      "网络设置完毕，学习的权重也加载完成\n"
     ]
    }
   ],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21, \n",
    "    'input_size': 300, \n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  \n",
    "    'steps': [8, 16, 32, 64, 100, 300],  \n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  \n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  \n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "\n",
    "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "\n",
    "\n",
    "vgg_weights = torch.load('./weights/vgg16_reducedfc.pth')\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None: \n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备为\", device)\n",
    "\n",
    "print('网络设置完毕，学习的权重也加载完成')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d17c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575681dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建模型\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用设备\", device)\n",
    "\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    # 当网络在一定程度稳定下来时开启高速运算\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  \n",
    "    epoch_val_loss = 0.0 \n",
    "    logs = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs+1):\n",
    "\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('轮数 {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "                print('（train）')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval() \n",
    "                    print('-------------')\n",
    "                    print('（val）')\n",
    "                else:\n",
    "\n",
    "                    continue\n",
    "\n",
    "\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "\n",
    "                     \n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 10 == 0):\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('迭代中 {} || 损失: {:.4f} || 10次迭代: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('轮 {} || Epoch_训练损失:{:.4f} ||Epoch_测试损失:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0 \n",
    "        epoch_val_loss = 0.0 \n",
    "\n",
    "\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/ssd300_' +\n",
    "                       str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f14686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备 cuda:0\n",
      "-------------\n",
      "轮数 1/1\n",
      "-------------\n",
      "（train）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\SSD_object_detection\\utils\\data_augumentation.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代中 10 || 损失: 15.8498 || 10次迭代: 11.5787 sec.\n",
      "迭代中 20 || 损失: 16.2861 || 10次迭代: 4.7393 sec.\n",
      "迭代中 30 || 损失: 12.0303 || 10次迭代: 4.7558 sec.\n",
      "迭代中 40 || 损失: 11.1153 || 10次迭代: 4.6213 sec.\n",
      "迭代中 50 || 损失: 12.6515 || 10次迭代: 4.6825 sec.\n",
      "迭代中 60 || 损失: 9.3104 || 10次迭代: 4.5508 sec.\n",
      "迭代中 70 || 损失: 9.7286 || 10次迭代: 4.6951 sec.\n",
      "迭代中 80 || 损失: 8.1316 || 10次迭代: 4.8813 sec.\n",
      "迭代中 90 || 损失: 10.5633 || 10次迭代: 4.6786 sec.\n",
      "迭代中 100 || 损失: 9.9221 || 10次迭代: 4.7664 sec.\n",
      "迭代中 110 || 损失: 9.7299 || 10次迭代: 5.0808 sec.\n",
      "迭代中 120 || 损失: 9.0026 || 10次迭代: 4.7954 sec.\n",
      "迭代中 130 || 损失: 8.5835 || 10次迭代: 5.0206 sec.\n",
      "迭代中 140 || 损失: 10.2168 || 10次迭代: 5.0497 sec.\n",
      "迭代中 150 || 损失: 9.1491 || 10次迭代: 4.6602 sec.\n",
      "迭代中 160 || 损失: 8.1679 || 10次迭代: 5.0231 sec.\n",
      "迭代中 170 || 损失: 8.1633 || 10次迭代: 4.8137 sec.\n",
      "迭代中 180 || 损失: 8.9868 || 10次迭代: 4.7568 sec.\n",
      "迭代中 190 || 损失: 8.1548 || 10次迭代: 4.8076 sec.\n",
      "迭代中 200 || 损失: 9.2872 || 10次迭代: 5.1040 sec.\n",
      "迭代中 210 || 损失: 9.1189 || 10次迭代: 5.1134 sec.\n",
      "迭代中 220 || 损失: 8.3029 || 10次迭代: 5.1419 sec.\n",
      "迭代中 230 || 损失: 8.7552 || 10次迭代: 5.1520 sec.\n",
      "迭代中 240 || 损失: 7.3963 || 10次迭代: 4.7999 sec.\n",
      "迭代中 250 || 损失: 7.8611 || 10次迭代: 4.6877 sec.\n",
      "迭代中 260 || 损失: 7.9989 || 10次迭代: 4.9083 sec.\n",
      "迭代中 270 || 损失: 8.0432 || 10次迭代: 4.8696 sec.\n",
      "迭代中 280 || 损失: 9.0353 || 10次迭代: 5.0099 sec.\n",
      "迭代中 290 || 损失: 8.8795 || 10次迭代: 4.9451 sec.\n",
      "迭代中 300 || 损失: 6.0342 || 10次迭代: 4.9267 sec.\n",
      "迭代中 310 || 损失: 9.3347 || 10次迭代: 4.8358 sec.\n",
      "迭代中 320 || 损失: 7.8459 || 10次迭代: 4.8352 sec.\n",
      "迭代中 330 || 损失: 8.1805 || 10次迭代: 4.7107 sec.\n",
      "迭代中 340 || 损失: 8.8493 || 10次迭代: 4.8793 sec.\n",
      "迭代中 350 || 损失: 8.3189 || 10次迭代: 4.7990 sec.\n",
      "迭代中 360 || 损失: 7.4616 || 10次迭代: 5.0199 sec.\n",
      "迭代中 370 || 损失: 9.0984 || 10次迭代: 4.9830 sec.\n",
      "迭代中 380 || 损失: 8.2558 || 10次迭代: 4.7406 sec.\n",
      "迭代中 390 || 损失: 8.3335 || 10次迭代: 5.0703 sec.\n",
      "迭代中 400 || 损失: 8.7663 || 10次迭代: 4.8733 sec.\n",
      "迭代中 410 || 损失: 7.5248 || 10次迭代: 4.8903 sec.\n",
      "迭代中 420 || 损失: 7.8071 || 10次迭代: 5.0143 sec.\n",
      "迭代中 430 || 损失: 6.8234 || 10次迭代: 4.9338 sec.\n",
      "迭代中 440 || 损失: 8.4592 || 10次迭代: 4.7942 sec.\n",
      "迭代中 450 || 损失: 6.3664 || 10次迭代: 4.8348 sec.\n",
      "迭代中 460 || 损失: 7.4176 || 10次迭代: 4.9046 sec.\n",
      "迭代中 470 || 损失: 8.6981 || 10次迭代: 4.8327 sec.\n",
      "迭代中 480 || 损失: 7.7115 || 10次迭代: 4.8589 sec.\n",
      "迭代中 490 || 损失: 7.6399 || 10次迭代: 4.6654 sec.\n",
      "迭代中 500 || 损失: 7.2709 || 10次迭代: 4.7550 sec.\n",
      "迭代中 510 || 损失: 8.8066 || 10次迭代: 4.7682 sec.\n",
      "迭代中 520 || 损失: 8.2471 || 10次迭代: 4.8928 sec.\n",
      "迭代中 530 || 损失: 7.1444 || 10次迭代: 4.7399 sec.\n",
      "迭代中 540 || 损失: 7.9939 || 10次迭代: 4.7932 sec.\n",
      "迭代中 550 || 损失: 8.4916 || 10次迭代: 4.9132 sec.\n",
      "迭代中 560 || 损失: 7.1407 || 10次迭代: 4.7999 sec.\n",
      "迭代中 570 || 损失: 6.5717 || 10次迭代: 4.7408 sec.\n",
      "迭代中 580 || 损失: 8.6538 || 10次迭代: 4.8858 sec.\n",
      "迭代中 590 || 损失: 7.8120 || 10次迭代: 4.8256 sec.\n",
      "迭代中 600 || 损失: 8.4948 || 10次迭代: 4.8225 sec.\n",
      "迭代中 610 || 损失: 7.4277 || 10次迭代: 5.1447 sec.\n",
      "迭代中 620 || 损失: 6.6654 || 10次迭代: 4.7834 sec.\n",
      "迭代中 630 || 损失: 6.0052 || 10次迭代: 4.7383 sec.\n",
      "迭代中 640 || 损失: 6.8246 || 10次迭代: 4.7779 sec.\n",
      "迭代中 650 || 损失: 7.6679 || 10次迭代: 4.7273 sec.\n",
      "迭代中 660 || 损失: 5.1945 || 10次迭代: 4.8290 sec.\n",
      "迭代中 670 || 损失: 7.9231 || 10次迭代: 4.8434 sec.\n",
      "迭代中 680 || 损失: 6.2372 || 10次迭代: 4.8502 sec.\n",
      "迭代中 690 || 损失: 6.6575 || 10次迭代: 4.9023 sec.\n",
      "迭代中 700 || 损失: 5.9554 || 10次迭代: 4.9950 sec.\n",
      "迭代中 710 || 损失: 7.1442 || 10次迭代: 4.7607 sec.\n",
      "迭代中 720 || 损失: 8.1837 || 10次迭代: 4.8057 sec.\n",
      "迭代中 730 || 损失: 8.1180 || 10次迭代: 4.7129 sec.\n",
      "迭代中 740 || 损失: 7.7728 || 10次迭代: 4.7849 sec.\n",
      "迭代中 750 || 损失: 6.7093 || 10次迭代: 4.8110 sec.\n",
      "迭代中 760 || 损失: 7.0953 || 10次迭代: 4.7433 sec.\n",
      "迭代中 770 || 损失: 6.6245 || 10次迭代: 5.1215 sec.\n",
      "迭代中 780 || 损失: 6.3491 || 10次迭代: 4.8995 sec.\n",
      "迭代中 790 || 损失: 9.0519 || 10次迭代: 4.7008 sec.\n",
      "迭代中 800 || 损失: 6.9289 || 10次迭代: 4.8209 sec.\n",
      "迭代中 810 || 损失: 7.8378 || 10次迭代: 4.6545 sec.\n",
      "迭代中 820 || 损失: 7.2664 || 10次迭代: 4.8437 sec.\n",
      "迭代中 830 || 损失: 7.3513 || 10次迭代: 4.9087 sec.\n",
      "迭代中 840 || 损失: 6.8641 || 10次迭代: 4.7994 sec.\n",
      "迭代中 850 || 损失: 6.7501 || 10次迭代: 4.6542 sec.\n",
      "迭代中 860 || 损失: 7.4695 || 10次迭代: 4.8592 sec.\n",
      "迭代中 870 || 损失: 8.3047 || 10次迭代: 4.7230 sec.\n",
      "迭代中 880 || 损失: 7.2962 || 10次迭代: 4.7031 sec.\n",
      "迭代中 890 || 损失: 6.6959 || 10次迭代: 4.8641 sec.\n",
      "迭代中 900 || 损失: 6.1733 || 10次迭代: 4.9599 sec.\n",
      "迭代中 910 || 损失: 7.2260 || 10次迭代: 4.8651 sec.\n",
      "迭代中 920 || 损失: 7.3744 || 10次迭代: 4.8738 sec.\n",
      "迭代中 930 || 损失: 6.7532 || 10次迭代: 4.9432 sec.\n",
      "迭代中 940 || 损失: 7.5974 || 10次迭代: 4.9177 sec.\n",
      "迭代中 950 || 损失: 7.8800 || 10次迭代: 4.8748 sec.\n",
      "-------------\n",
      "轮 1 || Epoch_训练损失:7814.1320 ||Epoch_测试损失:0.0000\n",
      "timer:  492.7411 sec.\n",
      "-------------\n",
      "轮数 2/1\n",
      "-------------\n",
      "（train）\n",
      "迭代中 960 || 损失: 7.4132 || 10次迭代: 3.3416 sec.\n",
      "迭代中 970 || 损失: 7.7448 || 10次迭代: 4.7710 sec.\n",
      "迭代中 980 || 损失: 7.2280 || 10次迭代: 4.7090 sec.\n",
      "迭代中 990 || 损失: 7.5464 || 10次迭代: 4.8722 sec.\n",
      "迭代中 1000 || 损失: 7.2071 || 10次迭代: 4.8981 sec.\n",
      "迭代中 1010 || 损失: 7.1331 || 10次迭代: 4.8378 sec.\n",
      "迭代中 1020 || 损失: 6.0813 || 10次迭代: 5.0170 sec.\n",
      "迭代中 1030 || 损失: 5.7506 || 10次迭代: 4.9383 sec.\n",
      "迭代中 1040 || 损失: 8.2065 || 10次迭代: 4.8959 sec.\n",
      "迭代中 1050 || 损失: 8.1539 || 10次迭代: 4.8859 sec.\n",
      "迭代中 1060 || 损失: 8.2216 || 10次迭代: 4.8798 sec.\n",
      "迭代中 1070 || 损失: 7.4617 || 10次迭代: 4.6342 sec.\n",
      "迭代中 1080 || 损失: 6.2097 || 10次迭代: 4.9060 sec.\n",
      "迭代中 1090 || 损失: 6.0750 || 10次迭代: 4.7626 sec.\n",
      "迭代中 1100 || 损失: 7.9974 || 10次迭代: 4.6871 sec.\n",
      "迭代中 1110 || 损失: 6.8142 || 10次迭代: 4.8326 sec.\n",
      "迭代中 1120 || 损失: 6.6591 || 10次迭代: 4.7623 sec.\n",
      "迭代中 1130 || 损失: 7.0094 || 10次迭代: 4.6584 sec.\n",
      "迭代中 1140 || 损失: 7.4875 || 10次迭代: 5.0572 sec.\n",
      "迭代中 1150 || 损失: 6.5811 || 10次迭代: 4.8432 sec.\n",
      "迭代中 1160 || 损失: 7.0692 || 10次迭代: 4.9138 sec.\n",
      "迭代中 1170 || 损失: 6.2167 || 10次迭代: 4.8287 sec.\n",
      "迭代中 1180 || 损失: 6.5358 || 10次迭代: 4.7952 sec.\n",
      "迭代中 1190 || 损失: 7.1008 || 10次迭代: 4.8271 sec.\n",
      "迭代中 1200 || 损失: 6.7726 || 10次迭代: 4.8204 sec.\n",
      "迭代中 1210 || 损失: 7.9587 || 10次迭代: 4.9592 sec.\n",
      "迭代中 1220 || 损失: 7.2545 || 10次迭代: 4.6874 sec.\n",
      "迭代中 1230 || 损失: 6.5375 || 10次迭代: 4.7309 sec.\n",
      "迭代中 1240 || 损失: 7.5831 || 10次迭代: 4.9767 sec.\n",
      "迭代中 1250 || 损失: 7.1894 || 10次迭代: 4.9386 sec.\n",
      "迭代中 1260 || 损失: 6.9401 || 10次迭代: 4.8137 sec.\n",
      "迭代中 1270 || 损失: 6.7569 || 10次迭代: 4.7936 sec.\n",
      "迭代中 1280 || 损失: 6.9413 || 10次迭代: 4.7492 sec.\n",
      "迭代中 1290 || 损失: 7.9870 || 10次迭代: 4.7282 sec.\n",
      "迭代中 1300 || 损失: 6.4520 || 10次迭代: 4.9239 sec.\n",
      "迭代中 1310 || 损失: 6.7140 || 10次迭代: 4.7189 sec.\n",
      "迭代中 1320 || 损失: 6.5258 || 10次迭代: 4.8527 sec.\n",
      "迭代中 1330 || 损失: 7.0740 || 10次迭代: 4.7218 sec.\n",
      "迭代中 1340 || 损失: 6.5640 || 10次迭代: 4.8446 sec.\n",
      "迭代中 1350 || 损失: 7.1689 || 10次迭代: 4.8366 sec.\n",
      "迭代中 1360 || 损失: 5.7731 || 10次迭代: 4.7257 sec.\n",
      "迭代中 1370 || 损失: 7.1006 || 10次迭代: 4.7206 sec.\n",
      "迭代中 1380 || 损失: 7.5581 || 10次迭代: 4.7347 sec.\n",
      "迭代中 1390 || 损失: 7.7172 || 10次迭代: 4.7254 sec.\n",
      "迭代中 1400 || 损失: 6.5855 || 10次迭代: 4.8011 sec.\n",
      "迭代中 1410 || 损失: 7.4764 || 10次迭代: 4.6539 sec.\n",
      "迭代中 1420 || 损失: 5.7985 || 10次迭代: 4.6635 sec.\n",
      "迭代中 1430 || 损失: 7.4783 || 10次迭代: 4.9545 sec.\n",
      "迭代中 1440 || 损失: 7.2260 || 10次迭代: 4.7512 sec.\n",
      "迭代中 1450 || 损失: 5.9468 || 10次迭代: 4.7424 sec.\n",
      "迭代中 1460 || 损失: 6.6373 || 10次迭代: 4.9982 sec.\n",
      "迭代中 1470 || 损失: 6.6001 || 10次迭代: 4.7569 sec.\n",
      "迭代中 1480 || 损失: 6.7139 || 10次迭代: 4.7369 sec.\n",
      "迭代中 1490 || 损失: 7.0291 || 10次迭代: 4.7856 sec.\n",
      "迭代中 1500 || 损失: 6.4163 || 10次迭代: 4.7105 sec.\n",
      "迭代中 1510 || 损失: 6.6097 || 10次迭代: 4.7477 sec.\n",
      "迭代中 1520 || 损失: 7.2383 || 10次迭代: 4.7260 sec.\n",
      "迭代中 1530 || 损失: 6.5788 || 10次迭代: 4.9982 sec.\n",
      "迭代中 1540 || 损失: 7.0577 || 10次迭代: 4.9433 sec.\n",
      "迭代中 1550 || 损失: 6.6894 || 10次迭代: 4.8462 sec.\n",
      "迭代中 1560 || 损失: 5.9567 || 10次迭代: 4.9628 sec.\n",
      "迭代中 1570 || 损失: 6.5789 || 10次迭代: 4.9104 sec.\n",
      "迭代中 1580 || 损失: 6.6637 || 10次迭代: 4.9266 sec.\n",
      "迭代中 1590 || 损失: 5.5257 || 10次迭代: 5.0801 sec.\n",
      "迭代中 1600 || 损失: 6.1284 || 10次迭代: 4.8218 sec.\n",
      "迭代中 1610 || 损失: 6.0143 || 10次迭代: 4.9026 sec.\n",
      "迭代中 1620 || 损失: 6.3386 || 10次迭代: 4.8321 sec.\n",
      "迭代中 1630 || 损失: 5.7841 || 10次迭代: 4.6825 sec.\n",
      "迭代中 1640 || 损失: 5.8339 || 10次迭代: 4.7675 sec.\n",
      "迭代中 1650 || 损失: 6.8045 || 10次迭代: 4.9574 sec.\n",
      "迭代中 1660 || 损失: 5.4423 || 10次迭代: 4.9714 sec.\n",
      "迭代中 1670 || 损失: 6.3745 || 10次迭代: 4.9909 sec.\n",
      "迭代中 1680 || 损失: 6.6914 || 10次迭代: 5.1658 sec.\n",
      "迭代中 1690 || 损失: 8.5444 || 10次迭代: 4.7834 sec.\n",
      "迭代中 1700 || 损失: 7.0492 || 10次迭代: 4.6992 sec.\n",
      "迭代中 1710 || 损失: 6.4274 || 10次迭代: 4.9338 sec.\n",
      "迭代中 1720 || 损失: 7.2600 || 10次迭代: 4.7125 sec.\n",
      "迭代中 1730 || 损失: 7.9786 || 10次迭代: 4.8892 sec.\n",
      "迭代中 1740 || 损失: 6.8611 || 10次迭代: 4.8297 sec.\n",
      "迭代中 1750 || 损失: 6.4597 || 10次迭代: 4.8779 sec.\n",
      "迭代中 1760 || 损失: 5.6973 || 10次迭代: 4.7327 sec.\n",
      "迭代中 1770 || 损失: 7.6858 || 10次迭代: 4.6719 sec.\n",
      "迭代中 1780 || 损失: 5.8267 || 10次迭代: 4.8598 sec.\n",
      "迭代中 1790 || 损失: 5.6662 || 10次迭代: 4.6406 sec.\n",
      "迭代中 1800 || 损失: 6.0743 || 10次迭代: 4.8049 sec.\n",
      "迭代中 1810 || 损失: 5.9257 || 10次迭代: 4.8601 sec.\n",
      "迭代中 1820 || 损失: 6.6345 || 10次迭代: 4.8509 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代中 1830 || 损失: 8.5794 || 10次迭代: 5.0208 sec.\n",
      "迭代中 1840 || 损失: 5.7758 || 10次迭代: 4.9335 sec.\n",
      "迭代中 1850 || 损失: 7.4043 || 10次迭代: 5.1143 sec.\n",
      "迭代中 1860 || 损失: 6.4769 || 10次迭代: 5.0922 sec.\n",
      "迭代中 1870 || 损失: 6.2332 || 10次迭代: 5.2038 sec.\n",
      "迭代中 1880 || 损失: 6.6885 || 10次迭代: 4.7933 sec.\n",
      "迭代中 1890 || 损失: 6.5419 || 10次迭代: 4.6957 sec.\n",
      "迭代中 1900 || 损失: 6.4178 || 10次迭代: 4.7635 sec.\n",
      "-------------\n",
      "轮 2 || Epoch_训练损失:6505.2705 ||Epoch_测试损失:0.0000\n",
      "timer:  482.4275 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs= 1\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c71864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict() , \"weights/ssd300_50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a405d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D2l_env",
   "language": "python",
   "name": "douhuanmin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
